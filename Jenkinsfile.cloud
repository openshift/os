def TIMER = "H H/3 * * *"
def NODE = "rhcos-imgfac-jslave"
def DOCKER_IMG = "quay.io/cgwalters/coreos-assembler"
def DOCKER_ARGS = "--net=host -v /srv:/srv --privileged"

// this var conveniently refers to a location on the server as well as the
// local dir we sync to/from
def images = "/srv/rhcos/output/images"

def ref = "openshift/3.10/x86_64/os";

node(NODE) {
    docker.image(DOCKER_IMG).pull()

    checkout scm
    utils = load("pipeline-utils.groovy")
    utils.define_properties(TIMER)

    stage("Provision") {
        sh """
           rpm -q imagefactory-plugins-TinMan \
                  libguestfs-tools-c \
                  rpm-ostree \
                  rsync || \
               dnf -y install ostree \
                              imagefactory-plugins-TinMan \
                              libguestfs-tools-c \
                              rpm-ostree \
                              rsync
           """
    }

    stage("Sync In") {
        withCredentials([
            string(credentialsId: params.ARTIFACT_SERVER, variable: 'ARTIFACT_SERVER'),
            sshUserPrivateKey(credentialsId: params.ARTIFACT_SSH_CREDS_ID, keyFileVariable: 'KEY_FILE'),
        ]) {
            utils.rsync_dir_in(ARTIFACT_SERVER, KEY_FILE, images)
        }

        // Also initialize an ostree repo for change detection
        withCredentials([
            string(credentialsId: params.OSTREE_INSTALL_URL, variable: 'OSTREE_INSTALL_URL'),
        ]) {
            sh """
                rm -rf repo && ostree init --repo=repo --mode=bare-user
                ostree --repo=repo remote add tmp --no-gpg-verify ${OSTREE_INSTALL_URL}
                ostree --repo=repo pull --commit-metadata-only tmp ${ref}
            """
        }
    }

    // Check if there's a new version out.
    // Really, we should be checksumming e.g. the ks and tdl too.
    def latest_version, last_build_version, force_nocache
    stage("Check for Changes") {
        latest_version = utils.get_rev_version("repo", "tmp:${ref}")
        if (fileExists('force-nocache-build')) {
            force_nocache = readFile('force-nocache-build').trim();
        }
        last_build_version = utils.sh_capture("cat ${images}/cloud/latest/version.txt || :")
    }

    if (latest_version == last_build_version && latest_version != force_nocache) {
        currentBuild.result = 'SUCCESS'
        currentBuild.description = '(No changes)'
        return
    }

    stage("Prepare Configs") {
        withCredentials([
            string(credentialsId: params.OSTREE_INSTALL_URL, variable: 'OSTREE_INSTALL_URL'),
            string(credentialsId: params.INSTALLER_TREE_URL, variable: 'INSTALLER_TREE_URL'),
        ]) {
            sh "sed -i 's,\\(<url>\\).*\\(<\\/url\\),\\1${INSTALLER_TREE_URL}\\2,' rhcos.tdl"
            sh "sed -i 's,@@OSTREE_INSTALL_URL@@,${OSTREE_INSTALL_URL},' cloud.ks"
            sh "sed -i 's,@@OSTREE_INSTALL_REF@@,${ref},' cloud.ks"
            sh "rm -rf /var/lib/imagefactory/storage/*"
        }
    }

    stage("Running imagefactory") {
        sh """
            imagefactory --debug base_image \
                --file-parameter install_script cloud.ks \
                --parameter offline_icicle True \
                rhcos.tdl
        """
    }

    def commit, version, dirpath, qcow, vmdk
    stage("Finalizing") {
        def image = utils.sh_capture("ls /var/lib/imagefactory/storage/*.body")
        // just introspect after the fact to avoid race conditions
        commit = utils.sh_capture("""
            LIBGUESTFS_BACKEND=direct virt-cat -a ${image} -m /dev/coreos/root:/ \
                /ostree/repo/refs/remotes/rhcos/${ref}
        """)

        // do this again *after* running imgfac to close race
        // fetch parent too for the later db diff
        sh "ostree --repo=repo pull --depth=1 --commit-metadata-only tmp ${commit}"
        version = utils.get_rev_version("repo", commit)
        currentBuild.description = "${version} (${commit})"

        def dirname = (new Date()).format("YYYY-MM-dd-HH-mm-ss-") + commit
        dirpath = "${images}/cloud/${dirname}"
        qcow = "${dirpath}/rhcos.qcow2"
        vmdk = "${dirpath}/rhcos.vmdk"
        sh "mkdir -p ${dirpath}"
        // this belongs better in a JSON file, but for now just use a file;
        // this is used higher up to determine no-op changes
        sh "echo '${version}' > ${dirpath}/version.txt"

        sh "qemu-img convert -f raw -O qcow2 ${image} ${qcow}"
        sh "gzip ${qcow}"
        sh "qemu-img convert -f raw -O vmdk ${image} -o adapter_type=lsilogic,subformat=streamOptimized,compat6 ${vmdk}"

        sh "ln -sfn ${dirname} ${images}/cloud/latest"
        // just keep the last 2 (+ latest symlink)
        sh "cd ${images}/cloud && (ls | head -n -3 | xargs -r rm -rf)"
    }

    stage("Generate Metadata") {
        // we're stuck with an older host because imagefactory produces kernel
        // panics on newer hosts, so let's use a container to have access to a
        // newer rpm-ostree that understands the new pkglist metadata
        docker.image(DOCKER_IMG).inside(DOCKER_ARGS) {
            def prev_commit = utils.sh_capture("ostree --repo=repo rev-parse ${commit}^")

            sh """
                rpm-ostree db list --repo=repo ${commit} > /${dirpath}/pkglist.txt
                rpm-ostree db diff --repo=repo ${prev_commit} ${commit} > ${dirpath}/pkgdiff.txt
                sha256sum ${qcow}.gz | awk '{print \$1}' > ${qcow}.gz.sha256sum
                sha256sum ${vmdk} | awk '{print \$1}' > ${vmdk}.sha256sum
            """
        }
    }

   if (params.DRY_RUN) {
       echo "DRY_RUN set, skipping push"
       currentBuild.result = 'SUCCESS'
       currentBuild.description = '(dry run)'
       return
   }

    stage("Sync Out") {
        withCredentials([
            string(credentialsId: params.ARTIFACT_SERVER, variable: 'ARTIFACT_SERVER'),
            sshUserPrivateKey(credentialsId: params.ARTIFACT_SSH_CREDS_ID, keyFileVariable: 'KEY_FILE'),
        ]) {
            utils.rsync_dir_out(ARTIFACT_SERVER, KEY_FILE, images)
        }
    }

    stage("Create AMI") {
        docker.image(DOCKER_IMG).inside(DOCKER_ARGS) {
            withCredentials([
                [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: params.AWS_CREDENTIALS],
                string(credentialsId: params.S3_PRIVATE_BUCKET, variable: 'S3_PRIVATE_BUCKET'),
            ]) {
                sh """
                    # use a symlink so that our uploaded filename is unique
                    ln -sf ${images}/cloud/latest/rhcos.vmdk rhcos-${commit}.vmdk
                    ore aws upload --region us-east-1 \
                        --ami-name 'rhcos_dev_${commit[0..6]}' \
                        --ami-description 'Red Hat CoreOS ${version} (${commit})' \
                        --bucket 's3://${S3_PRIVATE_BUCKET}/rhcos/cloud' \
                        --file rhcos-${commit}.vmdk \
                        --name "rhcos_dev_${commit[0..6]}" \
                        --delete-object | tee out.json # already default, just being explicit

                    # Add the version and commit as tags to both the AMI and the underlying snapshot.
                    # We should teach mantle to apply extra tags.
                    ami=\$(jq -r .HVM out.json)
                    snapshot=\$(jq -r .SnapshotID out.json)
                    AWS_DEFAULT_REGION=us-east-1 aws ec2 create-tags \
                        --resources \${ami} \${snapshot} \
                        --tags Key=ostree_commit,Value=${commit} \
                               Key=ostree_version,Value=${version}
                """
            }
        }
    }
}
