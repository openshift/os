def TIMER = "H H/3 * * *"
def NODE = "rhcos-jenkins"

// Are there really other regions?  We're sending explorers to find out
def AWS_REGION = "us-east-1"

// this var conveniently refers to a location on the server as well as the
// local dir we sync to/from
def images = "/srv/rhcos/output/images"

node(NODE) {
    def par_stages = [:]
    stage("Clean workspace") {
       step([$class: 'WsCleanup'])
    }
    checkout scm
    utils = load("pipeline-utils.groovy")
    utils.define_properties(TIMER)

    def manifest = "host-maipo.yaml"
    def manifest_data = readYaml file: "${manifest}";
    def ref = manifest_data.ref;

    utils.inside_assembler_container("-v /srv:/srv") {
    stage("Clone qcow2-to-vagrant") {
        // I tried to use git() but not sure where that went, it isn't the workspace
        sh('git clone https://github.com/cgwalters/qcow2-to-vagrant')
    }

    stage("Sync In") {
        withCredentials([
            string(credentialsId: params.ARTIFACT_SERVER, variable: 'ARTIFACT_SERVER'),
            sshUserPrivateKey(credentialsId: params.ARTIFACT_SSH_CREDS_ID, keyFileVariable: 'KEY_FILE'),
        ]) {
            sh "mkdir -p ${images}"
            utils.rsync_dir_in(ARTIFACT_SERVER, KEY_FILE, images)
        }

        // Also initialize an ostree repo for change detection
        withCredentials([
            string(credentialsId: params.OSTREE_INSTALL_URL, variable: 'OSTREE_INSTALL_URL'),
        ]) {
            sh """
                rm -rf repo && ostree init --repo=repo --mode=bare-user
                ostree --repo=repo remote add rhcos --no-gpg-verify ${OSTREE_INSTALL_URL}
                ostree --repo=repo pull --mirror --commit-metadata-only rhcos
            """
        }
    }

    // Check if there's a new version out.
    // Really, we should be checksumming e.g. the ks and tdl too.
    def latest_commit, last_build_meta, latest_version, force_nocache
    stage("Check for Changes") {
        latest_commit = utils.sh_capture("ostree --repo=repo rev-parse ${ref}")
        latest_version = utils.get_rev_version("repo", "${latest_commit}")
        if (fileExists('force-nocache-build')) {
            force_nocache = readFile('force-nocache-build').trim();
        }
        def previous = "${images}/cloud/latest";
        def previous_meta_path = "${previous}/meta.json";
        // I tried with fileExists before, but that only operates on ${WORKSPACE}
        if (sh(script: "stat ${previous_meta_path}>/dev/null", returnStatus: true) == 0) {
            // readJSON only operates on the ${WORKSPACE} too
            sh "cp --reflink=auto ${previous_meta_path} ${WORKSPACE}/previous-meta.json";
            last_build_meta = readJSON file: "previous-meta.json";
            echo "Previous build: ${last_build_meta}";
        } else {
            echo "No previous build.";
        }
    }

    def previously_built_commit = (last_build_meta != null && latest_commit == last_build_meta["ostree-commit"]);
    if (!params.DRY_RUN && previously_built_commit && latest_commit != force_nocache) {
        echo "Last built ${latest_version} (${latest_commit}) - no changes"
        currentBuild.result = 'SUCCESS'
        currentBuild.description = '(No changes)'
        return
    }

    stage("Prepare Configs") {
        withCredentials([
            string(credentialsId: params.OSTREE_INSTALL_URL, variable: 'OSTREE_INSTALL_URL'),
        ]) {
            sh "sed -i 's,@@OSTREE_INSTALL_URL@@,${OSTREE_INSTALL_URL},' cloud.ks"
            sh "sed -i 's,@@OSTREE_INSTALL_REF@@,${ref},' cloud.ks"
        }
    }

    // Note this runs unprivileged to avoid the virt stack trying to use privileges
    // We run in bwrap which sets up a pid namespace +init to ensure qemu is reaped,
    // which libvirt relies on.
    def image = "/tmp/rhcos.qcow2"
    try {
    withCredentials([
        string(credentialsId: params.INSTALLER_TREE_URL, variable: 'INSTALLER_TREE_URL')]) {
    stage("Running coreos-virt-install") { sh """
        chmod a+rw /dev/kvm
        setfacl -m u:builder:rwX ${WORKSPACE}
        bwrap --bind / / --dev-bind /dev /dev --proc /proc --unshare-pid runuser -u builder -- coreos-virt-install --dest ${image} --create-disk \
                --console-log-file ${WORKSPACE}/rhcos-qcow2-install.txt \
                --wait=25 --kickstart cloud.ks --location "${INSTALLER_TREE_URL}"
        """
    } }
    } finally {
        archiveArtifacts artifacts: "rhcos-qcow2-install.txt", allowEmptyArchive: true
    }

    // Quick kola sanity test
    try {
    stage("Kola rhcos.basic") { sh """
        kola version
        if ! kola -b rhcos --tapfile rhcos-basic.tap --qemu-image ${image} run rhcos.basic; then
          cp ${image} ${WORKSPACE}
          exit 1
        fi
    """ }
    } finally {
        sh 'tar -cJf _kola_temp.tar.xz _kola_temp'
        archiveArtifacts artifacts: "_kola_temp.tar.xz", allowEmptyArchive: true
        archiveArtifacts artifacts: "rhcos-basic.tap", allowEmptyArchive: true
        archiveArtifacts artifacts: "${image}", allowEmptyArchive: true
    }

    // We write this to meta.json
    def meta = [:];
    Integer image_genver;
    if (previously_built_commit) {
        image_genver = Integer.parseInt(last_build_meta["image-genver"]) + 1;
    } else {
        image_genver = 1;
    }
    meta["image-genver"] = image_genver;
    def img_prefix, commit, version, dirpath, qcow, vmdk, ec2, vagrant_libvirt
    stage("Postprocessing") {
        // just introspect after the fact to avoid race conditions
        // FIXME: Use labels like https://github.com/coreos/coreos-assembler/pull/95
        // But probably better to ditch all of this and use the assembler
        commit = utils.sh_capture("""
            LIBGUESTFS_BACKEND=direct virt-cat -a ${image} -m /dev/sda2:/ \
                /ostree/repo/refs/remotes/rhcos/${ref}
        """)

        // do this again *after* running imgfac to close race
        sh "ostree --repo=repo pull --mirror --depth=0 --commit-metadata-only rhcos ${commit}"
        version = utils.get_rev_version("repo", commit)
        meta["git-commit"] = utils.sh_capture("git describe --tags --always --abbrev=42");
        meta["ostree-commit"] = commit;
        meta["ostree-version"] = version;
        meta["image-genver"] = "${image_genver}";
        meta["image-version"] = "${version}-${image_genver}";
        currentBuild.description = "${meta['image-version']} (${commit})"

        dirpath = "${images}/cloud/${meta['image-version']}"
        img_prefix = "${dirpath}/rhcos-${version}"
        qcow = "${img_prefix}.qcow2"
        vmdk = "${img_prefix}.vmdk"
        ec2 = "${img_prefix}.ami"
        vagrant_libvirt = "${img_prefix}-vagrant-libvirt.box"
        sh "mkdir -p ${dirpath}"
        sh "mv ${image} ${qcow}"

        writeFile file: "meta.json", text: groovy.json.JsonOutput.toJson(meta);
        archiveArtifacts artifacts: "meta.json";
        sh "cp --reflink=auto ${WORKSPACE}/meta.json ${dirpath}/meta.json";
    }
    // These three are generated from the QCOW2
    par_stages["vmdk"] = { -> stage("Generate vmdk") {
        sh """coreos-oemid ${qcow} ${vmdk}.tmp vmware
              qemu-img convert -f qcow2 -O vmdk ${vmdk}.tmp -o adapter_type=lsilogic,subformat=streamOptimized,compat6 ${vmdk}
              rm ${vmdk}.tmp"""
    } }
    par_stages["ec2"] = { -> stage("Generate EC2") {
        sh """coreos-oemid ${qcow} ${WORKSPACE}/rhcos-aws.qcow2 ec2
              qemu-img convert -f qcow2 -O vmdk ${WORKSPACE}/rhcos-aws.qcow2 -o adapter_type=lsilogic,subformat=streamOptimized,compat6 ${ec2}
              rm ${WORKSPACE}/rhcos-aws.qcow2"""
    } }
    // We use direct as we hit SELinux issues otherwise
    par_stages["vagrant-libvirt"] = { -> stage("Generate vagrant-libvirt") { sh """
        env LIBGUESTFS_BACKEND=direct ${WORKSPACE}/qcow2-to-vagrant/qcow2-to-vagrant ${qcow} ${vagrant_libvirt}
        ln -sr ${vagrant_libvirt} ${dirpath}/rhcos-vagrant-libvirt.box
        """
    } }
    par_stages["openstack"] = { -> stage("Generate OpenStack") {
        def img_openstack = "${img_prefix}-openstack.qcow2"
        sh """coreos-oemid ${qcow} ${img_openstack} openstack
              gzip ${img_openstack}
              ln -sr ${img_openstack}.gz ${dirpath}/rhcos-openstack.qcow2.gz
              """
    } }
    // Execute parallel group
    parallel par_stages; par_stages = [:]

    stage("Finalizing, generate metadata") {
        // See https://github.com/openshift/installer/blob/master/Documentation/dev/libvirt-howto.md#13a-rhcos
        sh "qemu-img resize ${qcow} +8G"
        sh "gzip < ${qcow} > ${img_prefix}-qemu.qcow2.gz"
        sh "ln -sr ${img_prefix}-qemu.qcow2.gz ${dirpath}/rhcos-qemu.qcow2.gz"
        // Everything above in parallel worked on qcow, we're done with it now
        sh "rm ${qcow}"
        sh "ln -sfn ${meta['image-version']} ${images}/cloud/latest"
        // just keep the last 2 (+ latest symlink)
        sh "cd ${images}/cloud && (ls | head -n -3 | xargs -r rm -rf)"
        sh """
            rpm-ostree db list --repo=repo ${commit} > /${dirpath}/pkglist.txt
            cd ${dirpath} && find . -name '*.gz' -o -name '*.box' -o -name '*.vmdk' | \
            while read f; do
                test -f \${f}
                sha256sum \${f} | awk '{print \$1}' > \${f}.sha256sum
            done
        """
    }

   if (params.DRY_RUN) {
       echo "DRY_RUN set, skipping push"
       currentBuild.result = 'SUCCESS'
       currentBuild.description = '(dry run)'
       return
   }

    stage("Create Intermediate AMI") {
            withCredentials([
                [$class: 'AmazonWebServicesCredentialsBinding', credentialsId: params.AWS_CREDENTIALS],
                string(credentialsId: params.S3_PRIVATE_BUCKET, variable: 'S3_PRIVATE_BUCKET'),
                string(credentialsId: params.AWS_CI_ACCOUNT, variable: 'AWS_CI_ACCOUNT'),
            ]) {
                sh """
                    amijson=${dirpath}/aws-${AWS_REGION}-smoketested.json
                    ore aws upload --region ${AWS_REGION} \
                        --ami-name 'rhcos_dev_${commit[0..6]}' \
                        --ami-description 'Red Hat CoreOS ${version} (${commit})' \
                        --bucket 's3://${S3_PRIVATE_BUCKET}/rhcos/cloud' \
                        --file ${ec2} \
                        --name "rhcos_dev_${commit[0..6]}" \
                        --delete-object | tee \${amijson}

                    export AWS_DEFAULT_REGION=${AWS_REGION}

                    # Add the version and commit as tags to both the AMI and the underlying snapshot.
                    # We should teach mantle to apply extra tags.
                    ami=\$(jq -r .HVM \${amijson})
                    snapshot=\$(jq -r .SnapshotID \${amijson})
                    aws ec2 create-tags \
                        --resources \${ami} \${snapshot} \
                        --tags Key=ostree_commit,Value=${commit} \
                               Key=ostree_version,Value=${version}
                """
            }
    }

    par_stages["rsync-out"] = { -> stage("rsync out") {
        withCredentials([
            string(credentialsId: params.ARTIFACT_SERVER, variable: 'ARTIFACT_SERVER'),
            sshUserPrivateKey(credentialsId: params.ARTIFACT_SSH_CREDS_ID, keyFileVariable: 'KEY_FILE'),
        ]) {
            utils.rsync_dir_out(ARTIFACT_SERVER, KEY_FILE, images)
        }
    } }
    parallel par_stages; par_stages = [:]

    // Build the job responsible for testing and publishing the ami
    def ami_intermediate = utils.sh_capture("jq -r .HVM ${dirpath}/aws-${AWS_REGION}-smoketested.json")
    build job: 'coreos-rhcos-aws-test', wait: false, parameters: [
        string(name: 'ami_intermediate', value: "${ami_intermediate}"),
        string(name: 'dirpath', value: "${dirpath}"),
        string(name: 'aws_type', value: "t2.small")
    ]
    }
}
