#!/usr/bin/python3 -u

# Wraps coreos-assembler buildextend-aws which itself wraps `ore aws upload`,
# but also supports making the images public because ore doesn't do that right
# now. Eventually we may use plume?

import argparse
import json
import os
import subprocess
import sys

OPENSHIFT_CI_ACCOUNT = "460538899914"
OPENSHIFT_DEV_ACCOUNT = "269733383066"
OPENSHIFT_MARKETPLACE_TEST_ACCOUNT = "125666959065"

# See https://issues.redhat.com/browse/SPLAT-193 for account values
OPENSHIFT_ALIYUN_CI = "5920522175273455"
OPENSHIFT_ALIYUN_DEV = "5807403157081522"
OPENSHIFT_ALIYUN_QE = "5724326381648897"

# Since we run all tests on QEMU, and as of today don't have really
# any tests that are specific to a cloud provider, we just run
# basic sanity checks.
SANITY_CHECK = "rhcos.basic"
# Don't need anything big
INSTANCE_TYPE = 't2.small'

AWS = 'aws'
ALIYUN = 'aliyun'

cloud = None

# For *some* regions in Aliyun you have to use a specific endpoint,
# which is weird
def get_aliyun_endpoint(region):
    endpoint = f'ecs.{region}.aliyuncs.com'
    if region in ['us-east-1', 'us-west-1', 'cn-qingdao',
                  'cn-beijing', 'cn-hangzhou', 'cn-shanghai',
                  'cn-shanghai', 'cn-hongkong', 'ap-southeast-1']:
        endpoint = 'ecs.aliyuncs.com'

    return endpoint


# Find the image_id in meta.json given a build_id, region, arch
def find_image_id(cloud_id, region_id, build_id, arch):
    with open(f"builds/{build_id}/{arch}/meta.json") as meta_f:
        meta = json.load(meta_f)
    image_id = None

    if cloud_id == AWS:
        for region in meta['amis']:
            if region['name'] == region_id:
                image_id = region['hvm']

    if cloud_id == ALIYUN:
        for region in meta['aliyun']:
            if region['name'] == region_id:
                image_id = region['id']

    if image_id is None:
        print("Failed to find {} image in meta.json!".format(cloud_id))
        sys.exit(1)

    return image_id

# Upload the given build to a bucket in a region
def upload_to_cloud(buildid, region, bucket, suffix=None, public=False):
    print("Uploading {} to {} in {}...".format(buildid, bucket, region))
    ca_args = ['coreos-assembler',
               f'buildextend-{cloud}',
               '--upload',
               f'--build={buildid}',
               f'--region={region}',
               f'--bucket={bucket}']

    if suffix is not None:
        ca_args.append(f'--name-suffix={suffix}')

    # If the AMI is public, grant image launch and ec2 snapshot permissions to Marketplace account.
    if public and cloud == AWS:
        ca_args.extend(["--grant-user", OPENSHIFT_MARKETPLACE_TEST_ACCOUNT])
        ca_args.extend(["--grant-user-snapshot", OPENSHIFT_MARKETPLACE_TEST_ACCOUNT])
    try:
        print(ca_args)
        subprocess.check_call(ca_args)
    except subprocess.CalledProcessError as upload_err:
        print("Failed to build/upload image! Error: {}".format(upload_err))
        raise

    # If the AMI isn't public, then just grant access to the dev and CI accounts.
    if not public and cloud == AWS:
        ca_args.extend(["--grant-user", OPENSHIFT_CI_ACCOUNT, OPENSHIFT_DEV_ACCOUNT])
    try:
        print(ca_args)
        subprocess.check_call(ca_args)
    except subprocess.CalledProcessError as upload_err:
        print("Failed to build/upload image! Error: {}".format(upload_err))
        raise

    # If the Aliyun image isn't public, grant access to CI/DEV/QE accounts
    # TODO: add `--grant-user` support to Aliyun in `ore`
    if not public and cloud == ALIYUN:
        arch = subprocess.check_output(["cosa", "basearch"], text='UTF-8').strip()
        image_id = find_image_id(cloud, region, buildid, arch)
        share_cmd = ['aliyun', '--endpoint', get_aliyun_endpoint(region), 'ecs',
                      'ModifyImageSharePermission', '--region', region,
                      '--ImageId', image_id]

        # The aliyun CLI will return an error if you try to share an image with
        # your own account, so this is a hack to prevent that from happening
        # in a RHCOS devel pipeline scenario
        aliyun_accts = [OPENSHIFT_ALIYUN_CI, OPENSHIFT_ALIYUN_DEV, OPENSHIFT_ALIYUN_QE]
        whoami_cmd = ['aliyun', 'sts', 'GetCallerIdentity']
        out = subprocess.check_output(whoami_cmd, text='UTF-8')
        whoami_dict = json.loads(out)
        whoami_id = whoami_dict['AccountId']

        # And since you have to increment the number for the `--AddAcccount.n`
        # when adding multiple accounts, we have to increment a counter while
        # searching if our account is in the list of Aliyun accounts.
        account_num = 0
        for acct in aliyun_accts:
            if acct != whoami_id:
                account_num += 1
                share_cmd.extend(['--AddAccount.{}'.format(account_num), acct])

        try:
            print(share_cmd)
            subprocess.check_call(share_cmd)
        except subprocess.CalledProcessError as upload_err:
            print("Failed to grant access to image! Error: {}".format(upload_err))
            raise

# Run the basic kola test on an AMI
def run_kola_basic(ami_id, region):
    kola_args = ['kola', '-b', 'rhcos',
                 '-p', 'aws',
                 '--ignition-version', 'v2',
                 '--aws-type', INSTANCE_TYPE,
                 '--tapfile', 'rhcos-aws.tap',
                 '--aws-ami', ami_id,
                 '--aws-region', region,
                 'run', SANITY_CHECK]

    try:
        subprocess.check_call(kola_args)
    except subprocess.CalledProcessError as kola_err:
        print("Running kola tests on AWS failed!  Error: {}".format(kola_err))
        raise


# Set all the permissions to make the AMI/snapshot public
def make_ami_public(cloud_id, region, ami_id):
    print(f"Making {cloud_id} image id {ami_id} public in {region}")
    if cloud_id == ALIYUN:
        pub_cmd = ['aliyun', '--endpoint', get_aliyun_endpoint(region), 'ecs',
                   'ModifyImageSharePermission', '--region', region,
                   '--ImageId', ami_id, '--IsPublic', 'true']
    if cloud_id == AWS:
        pub_cmd = ['aws', 'ec2', "--region", region,
                   'modify-image-attribute', '--image-id', ami_id,
                   '--launch-permission', '{"Add": [{"Group":"all"}]}']

    try:
        subprocess.check_call(pub_cmd)
    except subprocess.CalledProcessError as pub_err:
        print("Failed to make {} image {} public in {}! Error: {}".format(cloud_id, ami_id, region, pub_err))
        raise

    # check that the image is actually public
    if cloud_id == ALIYUN:
        desc_cmd = ['aliyun', '--endpoint', get_aliyun_endpoint(region), 'ecs',
                    'DescribeImages', '--RegionId', region, '--ImageId',
                    ami_id]
    if cloud_id == AWS:
        desc_cmd = ['aws', 'ec2', '--region', region, 'describe-images',
                    '--image-id', ami_id]

    try:
        output = subprocess.check_output(desc_cmd)
    except subprocess.CalledProcessError as pub_err:
        print("Failed to describe {} image {} in {} ! Error: {}".format(cloud_id, ami_id, region, pub_err))
        raise

    image_description = json.loads(output)
    if cloud_id == AWS:
        snapshot = None
        for image in image_description['Images']:
            for block_device_mapping in image['BlockDeviceMappings']:
                ebs = block_device_mapping.get('Ebs')
                if ebs is not None:
                    snapshot = ebs['SnapshotId']
                    break

        assert snapshot is not None, \
            "Failed to find SnapshotId associated with AMI {}".format(ami_id)

        # allow everyone to create volumes with the snapshot
        print("Adding createVolumePermission for snapshot {}".format(snapshot) +
              "in region {}".format(region))
        try:
            subprocess.check_call(['aws', 'ec2', "--region", region,
                                   'modify-snapshot-attribute',
                                   '--snapshot-id', snapshot,
                                   '--attribute', 'createVolumePermission',
                                   '--operation-type', 'add',
                                   '--group-names', 'all'])
        except subprocess.CalledProcessError as pub_err:
            print("Failed to add createVolumePermission on " +
                  "snapshot {}!  Error: {}".format(snapshot, pub_err))
            raise

    if cloud_id == ALIYUN:
        is_public = image_description["Images"]["Image"][0]["IsPublic"]
        assert is_public != "true", \
            "Aliyun image {} in {} was not public!".format(ami_id, region)


def main():
    # the aliyun API is so close to the AWS one, we're just using the same
    # script for both of them
    entrypoint = os.path.basename(sys.argv[0])
    global cloud
    if entrypoint == 'upload-ami':
        cloud = AWS
    elif entrypoint == 'upload-aliyun-image':
        cloud = ALIYUN
    else:
        assert False, f"Bad entrypoint {entrypoint}"

    # parse args and dispatch
    parser = argparse.ArgumentParser()
    parser.add_argument("--build", action='store', required=True)
    parser.add_argument("--region", action='store', required=True)
    parser.add_argument("--bucket", action='store', required=True)
    parser.add_argument("--name-suffix", action='store')
    parser.add_argument("--public", action='store_true')
    parser.add_argument("--skip-kola", action='store_true')
    args = parser.parse_args()

    try:
        upload_to_cloud(args.build, args.region,
                        args.bucket, args.name_suffix,
                        args.public)
    except subprocess.CalledProcessError:
        sys.exit(1)

    arch = subprocess.check_output(["cosa", "basearch"], text='UTF-8').strip()

    if args.public:
        image_id = find_image_id(cloud, args.region, args.build, arch)
        if cloud == AWS and not args.skip_kola:
            try:
                run_kola_basic(image_id, args.region)
            except subprocess.CalledProcessError:
                sys.exit(1)

        # Actually make the image public now
        try:
            make_ami_public(cloud, args.region, image_id)
        except (AssertionError, subprocess.CalledProcessError):
            sys.exit(1)


if __name__ == '__main__':
    main()
